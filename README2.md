# philomathia
Veille sur les Math√©matiques

D√©finition simple des notions suivantes avec au moins un exemple √† chaque
fois :

# Table des mati√®res

[D√©finitions courtes](#D√©finitionscourtes)
1. [Vecteur](#vecteur)
2. [Matrice](#matrice)
3. [Probabilit√© et Loi de probabilit√©](#probabilit√©-et-loi-de-probabilit√©)
4. [Variables ind√©pendantes](#variables-ind√©pendantes)
5. [Esp√©rance, Variance et √âcart type](#esp√©rance-variance-et-√©cart-type)
6. [Corr√©lation lin√©aire](#corr√©lation-lin√©aire)
7. [Moyenne, M√©diane, Maximum, Minimum](#moyenne-m√©diane-maximum-minimum)
8. [Quartiles en statistique](#quartiles-en-statistique)
9. [Boxplot en statistique](#boxplot-en-statistique)
10. [Histogramme en statistique](#histogramme-en-statistique)
11. [Th√©or√®me Central Limite](#th√©or√®me-central-limite)
12. [D√©riv√©e](#d√©riv√©e)

---

## D√©finitions courtes

**Vecteur**

Liste ordonn√©e de nombres, repr√©sentant souvent des points dans un espace multidimensionnel.

**Matrice**

Tableau rectangulaire de nombres organis√©s en lignes et colonnes, utilis√© pour les op√©rations lin√©aires.

**Probabilit√©, loi de probabilit√©**

Mesure de la chance qu'un √©v√©nement se produise ; la loi de probabilit√© d√©crit toutes les probabilit√©s possibles d'un ensemble d'√©v√©nements.

**Variables ind√©pendantes**

Variables sans relation directe entre elles ; la variation de l'une n'affecte pas la variation de l'autre.

**Esp√©rance, variance et √©cart type**

   - **Esp√©rance** : Moyenne th√©orique des valeurs d'une variable.
   - **Variance** : Mesure de la dispersion autour de la moyenne.
   - **√âcart type** : Racine carr√©e de la variance, indiquant la dispersion autour de la moyenne.

**Corr√©lation lin√©aire**

Mesure de la relation lin√©aire entre deux variables ; elle varie de -1 (corr√©lation inverse) √† +1 (corr√©lation directe).

**Moyenne, m√©diane, maximum, minimum**
   - **Moyenne** : Somme des valeurs divis√©e par leur nombre.
   - **M√©diane** : Valeur centrale d'un ensemble tri√©.
   - **Maximum** : Plus grande valeur.
   - **Minimum** : Plus petite valeur.

**Quartiles en statistique**

Valeurs qui divisent un ensemble de donn√©es en quatre parties √©gales.

**Boxplot en statistique**

Diagramme qui r√©sume la distribution des donn√©es en affichant les quartiles et les valeurs extr√™mes.

**Histogramme en statistique**

Graphique montrant la r√©partition des donn√©es en regroupant les valeurs en classes.

**Th√©or√®me central limite**

Th√©or√®me indiquant que la somme de variables al√©atoires ind√©pendantes suit une distribution normale lorsque le nombre de variables est suffisamment grand.

**D√©riv√©e**

Mesure de la variation instantan√©e d'une fonction ; repr√©sente le taux de changement d'une variable par rapport √† une autre.


## Vecteur

### En math√©matiques, un vecteur peut √™tre d√©fini de plusieurs fa√ßons :

1. Repr√©sentation g√©om√©trique :
Un vecteur est une quantit√© ayant une longueur, une direction et un sens.
Il est repr√©sent√© par une fl√®che allant d'un point √† un autre.

2. Liste ordonn√©e de nombres :
Un vecteur peut √™tre vu comme une liste ordonn√©e de nombres r√©els, g√©n√©ralement not√©e sous forme de colonne ou de ligne.
Par exemple :(x1,x2,...,xn)

3. √âl√©ment d'un espace vectoriel : En alg√®bre lin√©aire, un vecteur est un √©l√©ment d'un espace vectoriel, qui ob√©it √† certaines propri√©t√©s comme l'addition vectorielle et la multiplication scalaire.

### Un vecteur en statistique

1. Repr√©senter des √©chantillons : Un vecteur peut contenir les observations d'une variable particuli√®re pour un ensemble d'individus.

2. Stocker des variables multiples : Plusieurs caract√©ristiques d'un m√™me individu peuvent √™tre regroup√©es dans un vecteur.

## Matrice

D√©finition d'une matrice et son utilisation dans les calculs statistiques.



### Matrice avec Numpy

Il y a plusieurs m√©thodes pour cr√©er une matrice avec python :

```python
A = np.array([[1, 2], [ 3, 4]])

B = np.matrix([[1, 2], [3, 4]])

C = np.matrix('[1,2;3,4]', dtype=np.int32)

D = np.array([np.arange(1,3), np.arange(3,5)])

E = np.arange(1,5).reshape(2,2)
```


### D√©finition d'une matrice

Une matrice est une structure de donn√©es bidimensionnelle, dispos√©s en lignes et colonnes.
C'est donc une grille rectangulaire de nombres organis√©e en lignes et colonnes. Les matrices peuvent repr√©senter des transformations lin√©aires, c'est-√†-dire des op√©rations qui transforment un vecteur d'un espace vectoriel en un autre. Par exemple, une matrice \(A\) de dimensions \(m \times n\) peut transformer un vecteur \(x\) en un autre vecteur \(A x\).

**Addition de matrices** : 
\[
A + B
\]
o√π \(A\) et \(B\) ont les m√™mes dimensions.

**Multiplication de matrices** :
\[
A B
\]
o√π le nombre de colonnes de \(A\) doit √™tre √©gal au nombre de lignes de \(B\).

**Multiplication entre une matrice et un vecteur colonne**

- Matrice \( \boldsymbol{X} \) de taille \(\boxed{ m \times n }\)
- vecteur colonne \( \boldsymbol{x} \) de taille \(\boxed{ n \times 1 }\)
- La multiplication entre ces deux objets donne un vecteur colonne de taille \( \boxed{m \times 1 }\).




|matrice $\boldsymbol{X}$<br> $3 \times 2$<br>3 lignes, 2 colonnes|vecteur colonne $\boldsymbol{v}$<br> $2 \times 1 $<br>2 lignes, 1 colonne |
|-|-|
|$$ \boldsymbol{X} = \begin{pmatrix} x_{11} & x_{12} \\x_{21} & x_{22} \\x_{31} & x_{32} \end{pmatrix}$$|$$\boldsymbol{v} = \begin{pmatrix} v_1 \\ v_2 \end{pmatrix}$$|







La multiplication \( \boldsymbol{X} \times \boldsymbol{x} \) se fait en calculant les produits scalaires de chaque ligne de la matrice \( \boldsymbol{X} \) avec le vecteur \( \boldsymbol{v} \).

### \( \boldsymbol{X} \times \boldsymbol{v} \) :

1. **Premi√®re ligne** : \( x_{11} \cdot v_1 + x_{12} \cdot v_2 \)
2. **Deuxi√®me ligne** : \( x_{21} \cdot v_1 + x_{22} \cdot v_2 \)
3. **Troisi√®me ligne** : \( x_{31} \cdot v_1 + x_{32} \cdot v_2 \)

Cela donne un vecteur colonne r√©sultant de taille \( 3 \times 1 \) :

\[
\boldsymbol{X} \times \boldsymbol{v} = 
\begin{pmatrix} 
x_{11} \cdot v_1 + x_{12} \cdot v_2 \\
x_{21} \cdot v_1 + x_{22} \cdot v_2 \\
x_{31} \cdot v_1 + x_{32} \cdot v _2
\end{pmatrix}
\]

- La **matrice \( \boldsymbol{X} \)** est une matrice de 3 lignes et 2 colonnes.
- Le **vecteur colonne \( \boldsymbol{x} \)** a 2 √©l√©ments.
- La multiplication g√©n√®re un **vecteur colonne** r√©sultant de 3 √©l√©ments.

Cela montre que **la multiplication d'une matrice \( A \) de taille \( m \times n \) par un vecteur colonne \( \boldsymbol{x} \) de taille \( n \times 1 \)** donne un **vecteur colonne** de taille \( m \times 1 \).

### R√©sultat final :
\[
\boldsymbol{X} \times \boldsymbol{x} = \begin{pmatrix} y_1 \\ y_2 \\ y_3 \end{pmatrix}
\]
o√π chaque \( y_i \) repr√©sente le produit scalaire entre la \(i\)-√®me ligne de \( \boldsymbol{X} \) et le vecteur \( \boldsymbol{x} \).

---

En statistiques, elle peut repr√©senter :

- Un ensemble d'observations sur plusieurs variables
- Des donn√©es structur√©es pour l'analyse multivari√©e
- Des coefficients pour des syst√®mes d'√©quations

### Utilisation dans les calculs statistiques

- Repr√©sentation des donn√©es
- Analyse multivari√©e
- Calculs matriciels
- Mod√©lisation statistique
- Inf√©rence statistique

### Calcul matriciel
n'est possible que si le nombre de colonnes de la premi√®re matrice est √©gal au nombre de lignes de la seconde

La matrice r√©sultat aura autant de lignes que la premi√®re matrice et autant de colonnes que la seconde.

Le produit matriciel est possible dans les "2 sens" mais il n'est pas commutatif : N x M diff√©rent de M x N
Sauf avec une matrice identit√© ou une matrice nulle.
![](produitmatriciel.png)

**Produit matriciel**

**version 1 :**
$$c_{ij} = \sum_{k=1}^{n}a_{ik} \cdot b_{kj} $$

**Explications**
| Symbole | Signification | Repr√©sentation math√©matique |
|---------|---------------|---------------------------|
| Œ£ (sigma) | Somme | $$\sum$$ |
| Œ£ avec limites | Somme pour k allant de 1 √† n | $$ \sum_{k=1}^{n}$$ |


**Version 2 :**
$$c_{ij}  = a_{i1} \cdot b_{1j} + a_{i2} \cdot b_{2j} + \cdots + a_{in} \cdot b_{nj}$$

### Matrice identit√©
$$ \begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{pmatrix}$$

La multiplication d'une matrice par une matrice identit√© retourne la matrice originale.
Le produit scalaire avec une matrice identit√© est commutatif.

### Matrice inverse et d√©terminant
Matrice
$$ M = \begin{pmatrix}
a & b \\
c & d
\end{pmatrix}$$
Une matrice est inversible si et seulement si son d√©terminant est non nul :

det(M) $ \neq $ 0
$$det(M) = (a \times d) - (c \times b) \neq 0$$
On d√©finit alors $M^{-1}$ comme suit :
$$ M^{-1} = \frac{1}{det(M)} \times \begin{pmatrix}
d & -b \\
-c & a
\end{pmatrix} $$

## Probabilit√© et Loi de probabilit√©
Introduction aux probabilit√©s et aux lois de probabilit√©s comme la loi normale, la loi binomiale, etc.

## Variables ind√©pendantes
D√©finition et explication des variables ind√©pendantes dans le cadre des probabilit√©s et statistiques.

**variance** (carr√© de l'√©cart type) √©cart quadratique moyen avec la moyenne


## Esp√©rance, Variance et √âcart type
Formules et interpr√©tations de l'esp√©rance, de la variance et de l'√©cart type d'une distribution.



## Corr√©lation lin√©aire
Pr√©sentation de la corr√©lation lin√©aire, du coefficient de corr√©lation et de leur interpr√©tation.

### Corr√©lation Lin√©aire de Pearson
Coefficient de Corr√©lation de Pearson
est une mesure de la corr√©lation lin√©aire entre deux variables.

Il est not√© $ùëü$ et varie entre -1 et 1

$r >0 $  : Corr√©lation positive (lorsque l'une des variables augmente, l'autre tend √† augmenter aussi).

$r<0$ : Corr√©lation n√©gative (lorsque l'une des variables augmente, l'autre tend √† diminuer).

#### $r = 1$
Corr√©lation lin√©aire positive parfaite
Les variables augmentent ensemble de mani√®re lin√©aire.


#### $r = 0$
Aucune corr√©lation lin√©aire
Les variables sont ind√©pendantes ou la relation n'est pas lin√©aire.


#### $r = ‚àí1$
Corr√©lation lin√©aire n√©gative parfaite
Lorsque l'une des variables augmente, l'autre diminue de mani√®re lin√©aire.


#### Interpr√©tation de la force de la corr√©lation :

$‚à£r‚à£$ est la valeur absolue du coefficient de corr√©lation, donc :
- toujours positive.
- mesure uniquement la force de la relation sans tenir compte de la direction.

- $‚à£r‚à£=1$
  relation lin√©aire parfaite (positive ou n√©gative).

- $‚à£r‚à£$ proche de 0
  relation lin√©aire faible ou nulle, quelle que soit la direction.



#### La fonction Pandas `corr()`cr√©e une matrice de corr√©lation
Chaque cellule repr√©sente le coefficient de corr√©lation de Pearson entre deux variables. La valeur de la corr√©lation varie entre -1 et 1 :
1 : Corr√©lation positive parfaite (les variables augmentent ensemble).
0 : Aucune corr√©lation lin√©aire.
-1 : Corr√©lation n√©gative parfaite (lorsque l'une augmente, l'autre diminue).


#### Limites du coefficient de Pearson :
- N‚Äôindique pas une causalit√© mais simplement une association lin√©aire.
- Ne fonctionne bien que pour des relations lin√©aires.
- Si la relation entre les variables est non lin√©aire, Pearson pourrait donner 
r‚âà0, m√™me si les variables sont fortement li√©es (par exemple, relation quadratique).

Exemple
Supposons que deux variables, x et y, soient li√©es de fa√ßon lin√©aire. Si leur coefficient de corr√©lation de Pearson est 0,9, cela indique une relation lin√©aire positive forte, o√π des augmentations de x sont g√©n√©ralement associ√©es √† des augmentations de y.


#### Autres coefficients de corr√©lation
Pour capturer des relations non lin√©aires ou pour des types de donn√©es diff√©rents :

- **Corr√©lation de Spearman** : Utilis√©e pour mesurer la corr√©lation monotone (ordre des valeurs) entre deux variables, adapt√©e aux distributions non normales.

- **Corr√©lation de Kendall** : Utilis√©e pour mesurer la corr√©lation entre deux variables ordinales.




## Moyenne, M√©diane, Maximum, Minimum
D√©finitions des mesures de tendance centrale et des valeurs extr√™mes.

- count : Le nombre de valeurs non nulles dans chaque colonne.
- mean : La moyenne des valeurs, utile pour voir les valeurs centrales.
- std : L'√©cart-type, qui indique la dispersion des donn√©es autour de la moyenne.
- min et max : Les valeurs minimum et maximum, montrent l'√©tendue des valeurs.
- Les quartiles 25%, 50% (m√©diane), 75% : donnent une id√©e de la distribution des donn√©es.

## Quartiles en statistique
Explication des quartiles, de leur calcul et de leur r√¥le dans la description des donn√©es.

## Boxplot en statistique
Description et interpr√©tation du diagramme en bo√Æte (Boxplot).
![Bo√Æte √† moustacje ( boxplot)](img/boxplot.png)

## Histogramme en statistique
Explication de l'histogramme et de son utilit√© dans la repr√©sentation des distributions de donn√©es.

## Th√©or√®me Central Limite
Pr√©sentation et explication du th√©or√®me central limite et de son importance en statistique.

## D√©riv√©e
D√©finition de la d√©riv√©e et son application dans diff√©rents contextes, y compris la statistique.

D√©rivation : √©tude des variations en un point

Cela n'as pas de sens d'√©tudier les variation sur un point.
Soit une courbe qui repr√©sente un d√©placement, temps en abscisse, distance en ordonn√©e

**D√©riv√© selon Leibniz**
On veut signifier un changement infiniment petit d'une quantit√© t :
un tout petit peu plus de t = dt (notation de Leibnitz)
un tout petit peu plus de f = df

La pente de la s√©quence au point d'abcisse 1 vaut $\frac{df}{dt}_{(1)}$

![Deriv√© de leibnitz](img/derive_d.png)

